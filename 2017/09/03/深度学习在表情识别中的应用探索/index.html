<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="VcC-PHB4Om9SIR3Roqm7k1N-SHiBtQ6c3LJLVMKgU4U" />










  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,深度学习," />





  <link rel="alternate" href="/atom.xml" title="吴良超的学习笔记" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 positive、negative、neutral 三种，细分可以分为 neutral, angry, surprise, disgust, fear, happy, sad 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习在表情识别中的应用">
<meta property="og:url" content="http://wulc.github.io/2017/09/03/深度学习在表情识别中的应用探索/index.html">
<meta property="og:site_name" content="吴良超的学习笔记">
<meta property="og:description" content="本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 positive、negative、neutral 三种，细分可以分为 neutral, angry, surprise, disgust, fear, happy, sad 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/1iz1l8nkegrw8sayw5553e2a/image_1bqkulor8935til84914bc3ar9.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/blrft8frb82ztfjh71ce6yw9/image_1bqkuvvjd5qp1383rtm1qnu1kic1g.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/hiacwfsn4x5yfxn5vcs90czq/image_1bqkvqgl5rojlbnodhtsg89e37.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/whsoea7v38zuacj3dphvjp48/image_1bqkvpc901ufv189f19r6h4q1h1p2q.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/us19a0bhaicq371ravi14jxg/image_1bql06cuj1ket1mhveme1l4fvsu3k.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/umgxlvrjcwonbjt8dtk4elr8/image_1bqmnubbv1pvf68s1cemeqa1plo41.png">
<meta property="og:image" content="http://static.zybuluo.com/WuLiangchao/anjt1zof6bf2chz2nq5k25pd/image_1bqmosh7oqcsbfa1ksp56de2d4e.png">
<meta property="og:updated_time" content="2018-12-21T11:53:29.221Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习在表情识别中的应用">
<meta name="twitter:description" content="本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 positive、negative、neutral 三种，细分可以分为 neutral, angry, surprise, disgust, fear, happy, sad 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类">
<meta name="twitter:image" content="http://static.zybuluo.com/WuLiangchao/1iz1l8nkegrw8sayw5553e2a/image_1bqkulor8935til84914bc3ar9.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wulc.github.io/2017/09/03/深度学习在表情识别中的应用探索/"/>





  <title> 深度学习在表情识别中的应用 | 吴良超的学习笔记 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  








  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1258114456&web_id=1258114456" language="JavaScript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">吴良超的学习笔记</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            站内搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://wulc.github.io/2017/09/03/深度学习在表情识别中的应用探索/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="良超">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="http://wulc.me/files/profile.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="吴良超的学习笔记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="吴良超的学习笔记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                深度学习在表情识别中的应用
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-03T21:37:39+08:00">
                2017-09-03
              </time>
            

            

            
          </span>

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 <code>positive</code>、<code>negative</code>、<code>neutral</code> 三种，细分可以分为 <code>neutral</code>, <code>angry</code>, <code>surprise</code>, <code>disgust</code>, <code>fear</code>, <code>happy</code>, <code>sad</code> 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类问题。</p>
<p>本文主要讲述如何将深度学习应用在表情识别中，以及在图像分类中深度学习一些常用方法，如采用预训练的模型进行特征的提取，用数据集对预训练的模型进行 Fine-tunning，而这实际上又牵涉到了迁移学习。</p>
<a id="more"></a>
<p>之所以采用深度学习的方法，是因为深度学习中的网络（尤其是CNN）对图像具有较好的提取特征的能力，从而避免了人工提取特征的繁琐，人脸的人工特征包括常用的 68 个 <a href="http://www.learnopencv.com/facial-landmark-detection/" target="_blank" rel="external">Facial landmarks</a> 等其他的特征，而深度学习除了预测外，往往还扮演着特征工程的角色，从而省去了人工提取特征的步骤。下面首先讲述深度学习中常用的网络类型，然后讲述通过预训练的网络(经过ImageNet进行预训练)对图像提取特征，以及对预训练的网络采用自己的数据进行微调的 Fine-Tunning。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>表情识别中常用的数据集有 <a href="http://www.consortium.ri.cmu.edu/ckagree/" target="_blank" rel="external">CK+</a>， <a href="https://mmifacedb.eu/" target="_blank" rel="external">MMI</a>， <a href="http://www.kasrl.org/jaffe.html" target="_blank" rel="external">JAFFE</a>， <a href="http://www.emotionlab.se/resources/kdef" target="_blank" rel="external">KDEF</a>等，这些数据有些是短视频，有些是图片序列（记录一个表情的若干张图片），有些则是单张表情图片。</p>
<p>在训练时，需要根据实际的应用场景以及采用的模型的输入格式将这些数据集处理成相关格式，这里不在详细说明。</p>
<h2 id="网络类型"><a href="#网络类型" class="headerlink" title="网络类型"></a>网络类型</h2><p>假如采用深度学习中常用的网络层 cnn，rnn， fully-connect 等层组合成网络，那么具有非常多种的选择，这些网络的性能需要在实际任务中检验，而经过实践发现，某些网络结构往往在图像分类上具有较好的结果，如ImgeNet比赛中提出的一些列模型：AlexNet，GoogleNet（Inception), VGG， ResNet 等。这些网络已经经过了 ImageNet 这个数据集的考验，因此在图像分类问题中也常被采用。</p>
<p>至于网络的结构，往往是先通过若干层 CNN 进行图像特征的提取，然后通过全连接层进行非线性分类，这时的全连接层就类似与MLP，只是还加入了 dropout 等机制防止过拟合等，最后一层有几个分类就连接几个神经元，并且通过 softmax 变换得到样本属于各个分类的概率分布。如下是 AlexNet 的网络结构图</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><img src="http://static.zybuluo.com/WuLiangchao/1iz1l8nkegrw8sayw5553e2a/image_1bqkulor8935til84914bc3ar9.png" alt="AlexNet"></p>
<p>关于AlexNet 更详细的介绍可参考<a href="http://wulc.me/2017/05/15/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" target="_blank" rel="external">这篇文章</a>。</p>
<h3 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h3><p>而 Inception 是 Google 研发的一个深度神经网络，经历了四个版本 （也叫GoogLeNet），各个版本及其对应的论文如下，各个版本</p>
<p>[v1] Going Deeper with Convolutions, 6.67% test error, <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="external">http://arxiv.org/abs/1409.4842</a><br>[v2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test error, <a href="http://arxiv.org/abs/1502.03167" target="_blank" rel="external">http://arxiv.org/abs/1502.03167</a><br>[v3] Rethinking the Inception Architecture for Computer Vision, 3.5% test error,  <a href="http://arxiv.org/abs/1512.00567" target="_blank" rel="external">http://arxiv.org/abs/1512.00567</a><br>[v4] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test error,   <a href="http://arxiv.org/abs/1602.07261" target="_blank" rel="external">http://arxiv.org/abs/1602.07261</a> </p>
<p>Inception 的结构与前面的 AlexNet 的大同小异，其核心是多了 Inception 模块，而 Inception 模块的结构如下</p>
<p><img src="http://static.zybuluo.com/WuLiangchao/blrft8frb82ztfjh71ce6yw9/image_1bqkuvvjd5qp1383rtm1qnu1kic1g.png" alt="Inception moule"></p>
<p>Inception 模块使得网络的当前层可以通过多种方式从前一层网络提取特征，如上图通过了三种不同大小的卷积层以及一个池化层，然后将这些特征进行 concate 送到下一层。</p>
<p>如下是 Inception V3 的结构</p>
<p><img src="http://static.zybuluo.com/WuLiangchao/hiacwfsn4x5yfxn5vcs90czq/image_1bqkvqgl5rojlbnodhtsg89e37.png" alt="Inception V3"></p>
<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>VGG 并没有采用很新颖的结构，整个网络只是采用了 3X3 的卷积层以及 2X2 的池化层，但是层数比较深，就是这么一个靠两种简单网络层堆叠起来的网络，却在 ImageNet 比赛上取得了非常好的结果。VGG 主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能，越深的网络能够容纳更多数据的信息，对于更大的数据具有更好的效果，VGG整个网络的结构如下</p>
<p><img src="http://static.zybuluo.com/WuLiangchao/whsoea7v38zuacj3dphvjp48/image_1bqkvpc901ufv189f19r6h4q1h1p2q.png" alt="VGG"></p>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>前面 VGG 提到了网络的深度（层数）起到了一个非常重要的作用，但是如果只是简单地将层堆叠在一起，增加网络的深度并不会起太大作用。这是由于梯度消失和爆炸（vanishing/exploding gradient）问题，深层的网络很难训练。因为梯度反向传播到前一层，重复相乘可能使梯度无穷小。结果就是，随着网络的层数更深，其性能趋于饱和，甚至开始迅速下降。</p>
<p>而为了解决因深度增加而产生的性能下降问题， ResNet 引入一个“身份捷径连接”（identity shortcut connection），直接跳过一层或多层，如下图所示：</p>
<p><img src="http://static.zybuluo.com/WuLiangchao/us19a0bhaicq371ravi14jxg/image_1bql06cuj1ket1mhveme1l4fvsu3k.png" alt="ResNet"></p>
<p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="external">提出 ReNet 的这篇论文</a>指出，假设目标映射为 $H(x)$，这个模块并不是让 stacked layers 去直接拟合这个目标映射，而是去拟合残差 $F(x) := H(x)-x$，则拟合的 $H(x)$ 则变为了 $F(x) + x$, 论文假设优化残差 $F(x)$ 比优化 H(x) 更容易。</p>
<p>上面这段话基本翻译自提出 ResNet 这篇论文，更直观的理解就是每一层不仅仅只是能从前一层获取信息了，而是还可以从更前面的几层获取，而 ResNet 最开始的只是建单地将更前面几层的 x 直接加到当前层的输出，也就是 $F(x) + x$， 而 ResNet 的若干变体则对这部分直接传递的 $x$ 进行了处理，如通过卷积层等操作，但是其核心思想还是跨层连接从而获得更多的信息。</p>
<p>最开始提出的 ResNet 的结构如下</p>
<p><img src="http://static.zybuluo.com/WuLiangchao/umgxlvrjcwonbjt8dtk4elr8/image_1bqmnubbv1pvf68s1cemeqa1plo41.png" alt="ResNet"></p>
<h3 id="CNN-LSTM"><a href="#CNN-LSTM" class="headerlink" title="CNN-LSTM"></a>CNN-LSTM</h3><p>上面的模型均是对单张图像进行处理，但是还有一种模型是对连续图片 sequence 进行处理的，由于连续图片 sequence 包含了时序信息，因此通过将 CNN 与 RNN 进行结合对时序图片列进行预测。在表情识别中</p>
<p>CNN-LSTM 是将 CNN 与 LSTM 结合起来的一种模型，其基本结构如下，图片出自<a href="https://arxiv.org/pdf/1411.4389v4.pdf" target="_blank" rel="external">该论文</a></p>
<p><img src="http://static.zybuluo.com/WuLiangchao/anjt1zof6bf2chz2nq5k25pd/image_1bqmosh7oqcsbfa1ksp56de2d4e.png" alt="cnn-lstm"></p>
<p>其思想就是首先通过 cnn 提取每张图片的特征，然后将这些带时序的特征传入 LSTM 中，可以取每一个 LSTM 的输出进行平均后连接 softmax 进行输出，也可以直接取最后一个 LSTM 的输出连接 softmax 作为输出。</p>
<p>上面这些网络训练的时候均是通过 SGD 进行反向传播，某些会加入 momentum 等其他改进。</p>
<p>这些网络理解起来可能问题不大，但是如果要代码实现起来的话工作量并不小，好在已经有了若干框架实现了这些模型，在使用时直接调用即可，这里以最简单的框架 <a href="https://github.com/fchollet/keras" target="_blank" rel="external">Keras</a> 为例说明，Kreas 已经在<a href="https://github.com/fchollet/deep-learning-models" target="_blank" rel="external">这里</a>列出了一些实现的网络，可以参考其文档直接进行调用。</p>
<h2 id="预训练模型提取特征"><a href="#预训练模型提取特征" class="headerlink" title="预训练模型提取特征"></a>预训练模型提取特征</h2><p>上面提到的这些模型少则十几层，多则上百层，其参数数目也达到了百万级别，要训练这么庞大的一个网络，如果数据量不足，很容易会会导致整个网络过拟合（当然，如果训练epoch次数少，也会直接导致欠拟合）。</p>
<p>而在实际中，像 ImageNet 这种庞大的数据集很少，而且某些只是归少数大公司所有，假如个人或缺乏数据的小公司需要用到上面提到的网络时，那就是无米之炊了，因此在实际中使用时，往往不是从头开始训练一个很大的模型，而是采用下面提到的通过模型提取特征以及对模型进行 Fine-Tunning 的方法。</p>
<p>深度学习中的网络的一个好处就是，经过大规模数据集训练过后的，网络具有了抽取图像特征的特性，而抽取出来的图像的特征，跟实际要处理任务没有关系，也就是说经过 ImageNet 训练过后的网络，也可以用于表情识别中抽取人脸的特征，然后用这些特征再训练一个小一点的模型，如 Logistics Regression， SVM等，这时候的网络完全就是在扮演着一个自动特征工程的角色。</p>
<p>这里“通过网络提取的特征”往往指的是网络最后的某个全连接层的输出值，具体采用哪一层取决于后续处理所需的特征维数。</p>
<p>Keras 也提供了经过 ImageNet 预训练的一些模型，通过这些模型抽取图像特征的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">base_model = VGG19(weights=<span class="string">'imagenet'</span>)</span><br><span class="line">model = Model(input=base_model.input, output=base_model.get_layer(<span class="string">'block4_pool'</span>).output)</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">'elephant.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">block4_pool_features = model.predict(x)</span><br></pre></td></tr></table></figure>
<p>在实际测试时，用 VGG16 抽取图像的特征后再经过带 L1 正则化的Logistics Regression，再CK+上进行10-fold cross validation， 得到的准确率约为85%, 也说明了这种方法的有效性。</p>
<h2 id="对预训练模型进行微调-Fine-Tunning"><a href="#对预训练模型进行微调-Fine-Tunning" class="headerlink" title="对预训练模型进行微调(Fine-Tunning)"></a>对预训练模型进行微调(Fine-Tunning)</h2><p>上面通过预训练的网络提取特征的确有效果，但是这些经过预训练的网络基本都是在 ImageNet 数据集上进行训练的，而实际中的各种任务是千差万别的，光凭 ImageNet 是难以涵盖各个领域的需求的。</p>
<p>因此很自然会想到在预训练的网络基础上，用涉及到的具体任务中的数据集再次训练这个网络，从而让这个网络能够学习到这个数据集内的信息，这种方法也称为 Fine-Tunning。</p>
<p>Keras 的官方blog也写了一篇文章专门阐述这种方法，文章链接为 <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="external">https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a></p>
<p>在这篇文章中，并没有调整整个网络的参数，而是只调整了最后的几层卷积层和全连接层，文章称原因是越底层的卷积层所提取到的图像的特性越是有共性的特征，而越上层的卷积层提取的特征则越是跟具体的领域相关的，当然，到底要调整多少层，还取决于所拥有的数据量，另外，往往还会去掉网络最后的若干层，并根据实际的图像分类数目构建最后一层大小。</p>
<p>通过 Keras 进行 Fine-Tunning 的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"></span><br><span class="line">height, width, categoriees = <span class="number">128</span>, <span class="number">128</span>, <span class="number">7</span></span><br><span class="line"></span><br><span class="line">model_vgg19_conv = VGG19(weights = <span class="string">'imagenet'</span>, include_top = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># just fine-tune the top five convulutional layers</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model_vgg19_conv.layers[:<span class="number">-5</span>]: </span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create your own input format (here 128x128X3)</span></span><br><span class="line">input = Input(shape=(height, width, <span class="number">3</span>),name = <span class="string">'image_input'</span>)</span><br><span class="line"><span class="comment">#Use the generated model </span></span><br><span class="line">output_vgg19_conv = model_vgg19_conv(input)</span><br><span class="line"><span class="comment">#Add the fully-connected layers </span></span><br><span class="line">x = Flatten(name=<span class="string">'flatten'</span>)(output_vgg19_conv)</span><br><span class="line">x = Dense(feature_dim, activation=<span class="string">'relu'</span>, name=<span class="string">'fc1'</span>)(x)</span><br><span class="line"><span class="comment"># x = Dense(feature_dim, activation='relu', name='fc2')(x)</span></span><br><span class="line">x = Dense(categories, activation=<span class="string">'softmax'</span>, name=<span class="string">'predictions'</span>)(x)</span><br><span class="line"><span class="comment">#Create your own model </span></span><br><span class="line">model = Model(inputs = input, outputs = x)</span><br></pre></td></tr></table></figure>
<p>最后讲的利用了预训练模型的两部分实际上可以归入到迁移学习的范畴了，原因是我们利用了模型在 ImageNet 上学到的知识，迁移到了一个新的领域(表情识别），同理，也可以将其推广至医学影像等领域，当然，迁移学习远不止这点内容，有兴趣的可以去查找相关资料，这里不在论述。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/28/python 中的字符串与编码/" rel="next" title="python 中的字符串与编码">
                <i class="fa fa-chevron-left"></i> python 中的字符串与编码
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/09/13/Spark 集群部署和 Jupyter Notebook 配置注意事项/" rel="prev" title="Spark 集群部署和 Jupyter Notebook 配置注意事项">
                Spark 集群部署和 Jupyter Notebook 配置注意事项 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://wulc.me/files/profile.jpg"
               alt="良超" />
          <p class="site-author-name" itemprop="name">良超</p>
          <p class="site-description motion-element" itemprop="description">======算法工程师首先得是个工程师=====关注计算广告，机器学习，文本处理</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">198</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/WuLC" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github-alt"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/wuliangchao/" target="_blank" title="Linkedin">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  Linkedin
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              推荐博客
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.flickering.cn/" title="火光摇曳" target="_blank">火光摇曳</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据集"><span class="nav-number">1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络类型"><span class="nav-number">2.</span> <span class="nav-text">网络类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Inception"><span class="nav-number">2.2.</span> <span class="nav-text">Inception</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG"><span class="nav-number">2.3.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ResNet"><span class="nav-number">2.4.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN-LSTM"><span class="nav-number">2.5.</span> <span class="nav-text">CNN-LSTM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预训练模型提取特征"><span class="nav-number">3.</span> <span class="nav-text">预训练模型提取特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对预训练模型进行微调-Fine-Tunning"><span class="nav-number">4.</span> <span class="nav-text">对预训练模型进行微调(Fine-Tunning)</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <center>
<div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2019</span>
  &nbsp;&nbsp;|&nbsp;&nbsp;Powered by <a href="http://hexo.io">Hexo</a> and <a href="http://theme-next.iissnan.com/">NexT</a></span>
  </br>
  <span>Documentation Licensed Under <a href="https://creativecommons.org/licenses/by/4.0/deed.en">CC BY 4.0</a></span>
</div>
</center>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  
<script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
